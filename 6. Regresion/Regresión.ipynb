{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión\n",
    "**Autor:** José A. Troyano &nbsp;&nbsp;&nbsp; **Revisor:** Beatriz Pontes &nbsp;&nbsp;&nbsp;     &nbsp;&nbsp;&nbsp; **Última modificación:** 31/03/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "## Contenido\n",
    "\n",
    "1. <a href=\"#entrenamiento\"> Entrenamiento de un regresor  </a> <br>\n",
    "    1.1. <a href=\"#regresion_lineal\"> Regresión lineal </a><br>\n",
    "    1.2. <a href=\"#estimador_reg_lin\"> El estimador _LinearRegression_ </a> <br>\n",
    "2. <a href=\"#evaluacion\"> Métricas de evaluación  </a> <br>\n",
    "3. <a href=\"#otros\"> Más regresores  </a> <br>\n",
    "4. <a href=\"#dilema\"> _Underfitting_, _good fitting_, _overfitting_ y el dilema sesgo-varianza </a> <br>\n",
    "    4.1. <a href=\"#visualizacion\"> Visualización de la predicción para regresión univariable  </a> <br>\n",
    "    4.2. <a href=\"#curva_dataset\">Curvas de aprendizaje en función del tamaño del conjunto de entrenamiento</a> <br>\n",
    "    4.3. <a href=\"#curva_complejidad\">Curvas de aprendizaje en función de la complejidad del modelo</a> <br>\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "En este _notebook_ veremos cómo entrenar y evaluar un regresor, exploraremos la oferta de regresores de Sklearn y veremos distintas técnicas para identificar situaciones de _overfitting_. \n",
    "\n",
    "Empezaremos por importar todos los elementos que usaremos a lo largo del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valle\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, validation_curve, learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset _concrete_, disponible en el repositorio UCI. El dataset contiene 1030 registros correspondientes a medidas de resistencia de hormigón. Los atributos se corresponden con las proporciones de la mezcla distintas muestras de hormigón y la edad (en días) de la muestra. La variable numérica a predecir es la resistencia de cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0      540.0                 0.0      0.0  162.0               2.5   \n",
       "1      540.0                 0.0      0.0  162.0               2.5   \n",
       "2      332.5               142.5      0.0  228.0               0.0   \n",
       "3      332.5               142.5      0.0  228.0               0.0   \n",
       "4      198.6               132.4      0.0  192.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "1025   276.4               116.0     90.3  179.6               8.9   \n",
       "1026   322.2                 0.0    115.6  196.0              10.4   \n",
       "1027   148.5               139.4    108.6  192.7               6.1   \n",
       "1028   159.1               186.7      0.0  175.6              11.3   \n",
       "1029   260.9               100.5     78.3  200.6               8.6   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  \n",
       "0               1040.0           676.0   28  \n",
       "1               1055.0           676.0   28  \n",
       "2                932.0           594.0  270  \n",
       "3                932.0           594.0  365  \n",
       "4                978.4           825.5  360  \n",
       "...                ...             ...  ...  \n",
       "1025             870.1           768.3   28  \n",
       "1026             817.9           813.4   28  \n",
       "1027             892.4           780.0   28  \n",
       "1028             989.6           788.9   28  \n",
       "1029             864.5           761.5   28  \n",
       "\n",
       "[1030 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: leer el fichero 'concrete.csv' y crear el dataframe 'X' para los atributos, y la serie 'y' para la clase (atributo 'Concrete compressive strength')\n",
    "datos = pd.read_csv(\"concrete.csv\")\n",
    "\n",
    "#Separar los atributos (X) de la clase (Y)\n",
    "X = datos.drop(columns=['Concrete compressive strength'])\n",
    "y = datos['Concrete compressive strength']\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entrenamiento de un regresor <a name=\"entrenamiento\"> </a>\n",
    "\n",
    "Entrenar un clasificador es muy simple en Sklearn, basta con crear un objeto del estimador que queramos entrenar y ejecutar el método <code>fit</code>. En este notebook usaremos uno de los regresores más comunes: <code>LinearRegression</code>.\n",
    "\n",
    "### 1.1 ¿Qué es la regresión lineal? <a name=\"regresion_lineal\"> </a>\n",
    "\n",
    "Es un modelo matemático usado para aproximar la relación entre una variable dependiente $y$, y las variables independientes $x_i$. El modelo se expresa con la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "y \\approx \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n\n",
    "$$\n",
    "\n",
    "Sklearn proporciona distinos métodos para realizar regresión lineal. El más simple de ellos es el de los _mínimos cuadrados_ que es el que implementa el estimador <code>LinearRegression</code>. La técnica de los mínimos cuadrados se utiliza para determinar los coeficientes de una función de regresión que minimicen la suma de los cuadrados de los errores. Para una función de regresión lineal, se trataría de minimizar esta expresión:\n",
    "\n",
    "$$\n",
    "S = \\sum (y - f(X))^2 = \\sum (y - \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n)^2\n",
    "$$\n",
    "\n",
    "\n",
    "### 1.2 El estimador <code>LinearRegression</code> <a name=\"estimador_reg_lin\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: crear un estimador de la clase LinearRegression y entrenarlo con el dataset <X,y>\n",
    "estimador = LinearRegression()\n",
    "estimador.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un estimador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.46346329, 53.73475651, 56.81258504, 67.66368153, 60.91205585,\n",
       "       26.85991563, 68.42076149, 29.92792448, 19.7781474 , 31.44208441])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: predecir la salida de los primeros 10 valores de X con el regresor entrenado anteriormente\n",
    "predicciones = estimador.predict(X.head(10))\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar validación cruzada para evaluar. Por defecto la métrica de evaluación es <code>r2_score</code> aunque, como veremos en la siguiente sección, hay más métricas implementadas en Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.31616047, 53.75523611, 61.10426739, 74.14150413, 68.48871563,\n",
       "       26.71337155, 74.56828326, 28.32040134, 18.20485915, 29.1739596 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: predecir la salida de todas las instancias mediante validación cruzada y guardar las prediccciones en y_pred\n",
    "y_pred = cross_val_predict(estimador, X, y, cv=10)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27820729160873797"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: calcular el score por defecto sobre todas las instancias mediante validación cruzada\n",
    "scores = cross_val_score(estimador, X, y, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6646785999576503"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: dividir el dataset <X, y> en dos datasets <X_train, y_train> y <X_test, y_test> con una distribución 80%-20%,\n",
    "#            entrenar el regresor con <X_train, y_train> y calcular la métrica r2 con <X_test, y_test>\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "estimador.fit(X_train, y_train)\n",
    "y_test_pred = estimador.predict(X_test)\n",
    "metrics.r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Métricas de evaluación <a name=\"evaluacion\"> </a>\n",
    "\n",
    "En las tareas de clasificación las métricas de evaluación se basan en el número de aciertos de las predicciones. En la regresión, sin embargo, no se puede hablar de aciertos ya que las predicciones son numéricas y es muy improbable predecir exactamente el valor correcto. Lo importante para evaluar un regresor es medir la diferencia entre el valor real y el valor predicho. \n",
    "\n",
    "En esta sección tres de las métricas más populares para evaluar la calidad de los regresores:\n",
    "Métricas de error (cuánto peor valor, mejor):\n",
    "- MAE: _mean absolute error_ (en términos de la magnitud a predecir)\n",
    "- MSE: _mean squared error_ (da más peso a los errores grandes)\n",
    "- MLSE: _mean squared logarithmic error_(da más peso a los errores pequeños, especialmente indicada cuando la variable a predecir presenta un rango muy amplio de valores)\n",
    "Métricas de acierto (cuánto mejor valor, mejor):\n",
    "- R2: coeficiente de determinación (normalizada de $-1$ a $1$\n",
    "\n",
    "Las fórmulas para cada una de las tres métricas son:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{\\sum |\\;y -f(X)\\;|}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum (y -f(X))^2}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "MLSE = \\frac{\\sum (log(y+1) - log(f(X)+1)) ^2}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "R2 = 1 - \\frac{\\sum (y -f(X))^2}{\\sum (\\bar{y} - y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5\n",
      "MSE: 0.375\n",
      "R2: -0.19999999999999996\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: dadas los siguientes vectores 'y_real' e 'y_pred' calcular las métricas MAE, MSE y R2\n",
    "#    y_real = [1,   0.5, 1.5, 0]\n",
    "#    y_pred = [1.5, 0,   1.5,  1]\n",
    "\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_real = [1, 0.5, 1.5, 0]\n",
    "y_pred = [1.5, 0, 1.5, 1]\n",
    "\n",
    "# Calcula MAE\n",
    "mae = metrics.mean_absolute_error(y_real, y_pred)\n",
    "\n",
    "# Calcula MSE\n",
    "mse = metrics.mean_squared_error(y_real, y_pred)\n",
    "\n",
    "# Calcula R2\n",
    "r2 = metrics.r2_score(y_real, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -1.333333333333333\n",
      "MSE: -2.4722222222222214\n",
      "R2: -33.61728395061727\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: calcular las métricas MAE, MSE y R2 usando 'cross_val_score' y el estimador LinearRegression\n",
    "# NOTA: los scores MAE y MSE son negativos para que los valores altos se correspondan con mejores resultados\n",
    "\n",
    "# Calcular los scores utilizando validación cruzada\n",
    "mae_scores = cross_val_score(estimador, np.array(y_real).reshape(-1, 1), y_pred, scoring='neg_mean_absolute_error', cv=2)\n",
    "mse_scores = cross_val_score(estimador, np.array(y_real).reshape(-1, 1), y_pred, scoring='neg_mean_squared_error', cv=2)\n",
    "r2_scores = cross_val_score(estimador, np.array(y_real).reshape(-1, 1), y_pred, scoring='r2', cv=2)\n",
    "\n",
    "# Calcular el promedio de los scores\n",
    "mae_avg = np.mean(mae_scores)\n",
    "mse_avg = np.mean(mse_scores)\n",
    "r2_avg = np.mean(r2_scores)\n",
    "\n",
    "print(\"MAE:\", mae_avg)\n",
    "print(\"MSE:\", mse_avg)\n",
    "print(\"R2:\", r2_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9999999999999997\n",
      "MSE: 1.2638888888888882\n",
      "R2: -3.0444444444444425\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: repetir el cálculo de la  métricas MAE usando 'cross_val_predict'\n",
    "y_pred_cv = cross_val_predict(estimador, np.array(y_real).reshape(-1, 1), y_pred, cv=2)\n",
    "\n",
    "# Calcula MAE\n",
    "mae_cv = mean_absolute_error(y_real, y_pred_cv)\n",
    "\n",
    "# Calcula MSE\n",
    "mse_cv = mean_squared_error(y_real, y_pred_cv)\n",
    "\n",
    "# Calcula R2\n",
    "r2_cv = r2_score(y_real, y_pred_cv)\n",
    "\n",
    "print(\"MAE:\", mae_cv)\n",
    "print(\"MSE:\", mse_cv)\n",
    "print(\"R2:\", r2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Más regresores <a name=\"otros\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección usaremos la función <code>experimento</code> con distintos regresores e iremos guardando los resultados en el _dataframe_ <code>RESULTADOS</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame donde iremos guardando los resultados de los experimentos\n",
    "RESULTADOS = pd.DataFrame(columns=['R2', 'TIEMPO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27820729160873797, 0.10506796836853027)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: implementar la función 'experimento' que encapsule todos los pasos del experimento de la sección anterior\n",
    "#    PARÁMETROS DE ENTRADA:\n",
    "#       - regresor: estimador usado en el experimento\n",
    "#       - X: matriz de atributos\n",
    "#       - y: vector de salida\n",
    "#       - scoring: métrica usada en la evaluación (por defecto 'r2')\n",
    "#    SALIDAS:\n",
    "#       - Devolver la tupla (score, tiempo) con la puntuación del experimento y el tiempo invertido en segundos\n",
    "def experimento(regresor, X, y, scoring='r2'):\n",
    "    inicio = time.time()\n",
    "    score = cross_val_score(regresor, X, y, scoring=scoring, cv=10).mean()\n",
    "    fin =  time.time()\n",
    "    return score, fin-inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m     mae \u001b[38;5;241m=\u001b[39m experimento(regresor,X,y, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m     mse \u001b[38;5;241m=\u001b[39m experimento(regresor,X,y, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m experimento(regresor,X,y, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m     RESULTADOS\u001b[38;5;241m.\u001b[39mloc[titulo] \u001b[38;5;241m=\u001b[39m (mae[\u001b[38;5;241m0\u001b[39m], mse[\u001b[38;5;241m0\u001b[39m], r2[\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m     47\u001b[0m                               np\u001b[38;5;241m.\u001b[39mmean([mae[\u001b[38;5;241m1\u001b[39m],mse[\u001b[38;5;241m1\u001b[39m],r2[\u001b[38;5;241m1\u001b[39m]]))\n\u001b[0;32m     48\u001b[0m RESULTADOS\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mexperimento\u001b[1;34m(regresor, X, y, scoring)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexperimento\u001b[39m(regresor, X, y, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     10\u001b[0m     inicio \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 11\u001b[0m     score \u001b[38;5;241m=\u001b[39m cross_val_score(regresor, X, y, scoring\u001b[38;5;241m=\u001b[39mscoring, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     12\u001b[0m     fin \u001b[38;5;241m=\u001b[39m  time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score, fin\u001b[38;5;241m-\u001b[39minicio\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[0;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_class_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    336\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    337\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    338\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    339\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    340\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    341\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    342\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    343\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    344\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    345\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    346\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    347\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    348\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    349\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "File \u001b[1;32msklearn\\svm\\_libsvm.pyx:265\u001b[0m, in \u001b[0;36msklearn.svm._libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# EJERCICIO: usar la función 'experimento' con los siguientes regresores y almacenar los resultados en el dataframe RESULTADOS:\n",
    "# - Regresión lineal\n",
    "# - Regresión lineal con Stochastic Gradient Descent Regressor\n",
    "# - Regresión cuadrática basada en Regresión Lineal (hay que usar Pipeline y PolynomialFeatures)\n",
    "# - Vecinos más cercanos, con valores para k en [1, 3, 5, 7]\n",
    "# - Support Vector Regressor, con valores para kernel en ['linear', ‘rbf’, ‘sigmoid’]\n",
    "# - Árbol de decisión\n",
    "# - Random Forests, con valores para n_estimators en [10, 100, 1000]\n",
    "# - Extra Trees, con valores para n_estimators en [10, 100, 1000]\n",
    "# - Gradient Boosting Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "regresores = [\n",
    "    (LinearRegression(),'Regresión lineal'),\n",
    "    (KNeighborsRegressor (1), 'Vecinos más cercanos - 1'),\n",
    "    (KNeighborsRegressor(3), 'Vecinos más cercanos - 3'),\n",
    "    (KNeighborsRegressor(5), 'Vecinos más cercanos - 5'),\n",
    "    (KNeighborsRegressor(7), 'Vecinos más cercanos - 7'),\n",
    "    (SVR(kernel='linear'), 'SVR - linear'),\n",
    "    (SVR(kernel='rbf'), 'SVR - rbf'),\n",
    "    (SVR(kernel='sigmoid'), 'SVR - sigmoid'),\n",
    "    (DecisionTreeRegressor(), 'Arbol de decisión'),\n",
    "    (RandomForestRegressor(n_estimators=10), 'RFR - 10'),\n",
    "    (RandomForestRegressor(n_estimators=100), 'RFR - 100'),\n",
    "    (RandomForestRegressor(n_estimators=1000), 'RFR - 1000'),\n",
    "    (ExtraTreesRegressor(n_estimators=10), 'ExtraTrees - 10'),\n",
    "    (ExtraTreesRegressor(n_estimators=100), 'ExtraTrees - 100'),\n",
    "    (ExtraTreesRegressor(n_estimators=1000), 'ExtraTrees - 1000'),\n",
    "    (GradientBoostingRegressor (), 'GBR')\n",
    "]\n",
    "\n",
    "#print(regresores)\n",
    "\n",
    "RESULTADOS = pd.DataFrame(columns=['MAE', 'MSE', 'R2', 'Tiempo medio'])\n",
    "\n",
    "for regresor,titulo in regresores:\n",
    "    mae = experimento(regresor,X,y, scoring='neg_mean_absolute_error')\n",
    "    mse = experimento(regresor,X,y, scoring='neg_mean_squared_error')\n",
    "    r2 = experimento(regresor,X,y, scoring='r2')\n",
    "    RESULTADOS.loc[titulo] = (mae[0], mse[0], r2[0], \n",
    "                              np.mean([mae[1],mse[1],r2[1]]))\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. _Underfitting_, _good fitting_, _overfitting_ y el dilema sesgo-varianza <a name=\"dilema\"> </a>\n",
    "\n",
    "La siguiente figura muestra gráficamente las situaciones de _underfitting_, _good fitting_, _overfitting_ en una tarea de regresión:\n",
    "\n",
    "<img src=\"./img/under-good-over.jpg\" alt=\"Drawing\" style=\"width:10cm;\"/>\n",
    "\n",
    "Se suelen considerar dos fuentes de error en los modelos entrenados a partir de datos:\n",
    "- **Sesgo (bias)**:\n",
    "    - Error producto de la simplificación (y pérdida de información) que implica la construcción de un modelo. \n",
    "    - Un _sesgo alto_ implica _underfitting_.\n",
    "- **Varianza (variance)**: \n",
    "    - Error producto de la dependencia de los datos usados. \n",
    "    - Mide el cambio que sufriría el modelo si se utilizaran datos de entrenamiento diferentes. \n",
    "    - Una _varianza alta_ implica _overfitting_.\n",
    "\n",
    "La siguiente gráfica muestra de forma intuitiva el efecto de ambos tipos de error.\n",
    "\n",
    "<img src=\"./img/bias-variance.jpg\" alt=\"Drawing\" style=\"width:10cm;\"/>\n",
    "\n",
    "El dilema _sesgo-varianza_ es el conflicto que se plantea al intentar minimzar ambas fuentes de error al entrenar un modelo. Hay una relación entre la complejidad del modelo y el dilema sesgo varianza que se suele ilustrar con una gráfica como la siguiente: \n",
    "\n",
    "<img src=\"./img/bias-variance-tradeoff.jpg\" alt=\"Drawing\" style=\"width:10cm;\"/>\n",
    "\n",
    "En la curva anterior se observan los siguientes fenómenos:\n",
    "- Modelos simples: adocelcen de _underfitting_ y presentan alto sesgo (error de predicción) y baja varianza (dependencia de los datos de entrenamiento)\n",
    "- Modelos complejos: adocelcen de _overfitting_ y presentan bajo sesgo (error de predicción) y alta varianza (dependencia de los datos de entrenamiento)\n",
    "\n",
    "\n",
    "Las curvas de aprendizaje basadas en la complejidad del modelo también nos permiten identificar situaciones de alto sesgo (_underfitting_) y de alta varianza (_overfitting_):\n",
    "\n",
    "<img src=\"./img/bias-variance-learning-curve.jpg\" alt=\"Drawing\" style=\"width:10cm;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Visualización de modelos para regresión univariable <a name=\"visualizacion\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='x', ylabel='x'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generamos un dataset para regresión univariable con las siguientes características:\n",
    "#    - X: dataframe de una única columna con 100 valores reales aleatorios entre 1 y 10\n",
    "#    - y: serie con la salida para cada x, con un valor x^2 (+/- un valor aleatorio entre 0 y 20)\n",
    "#   Mostrar los puntos en un scatter_plot\n",
    "np.random.seed(10)\n",
    "X = pd.DataFrame(np.random.random((100,))*9+1, columns=['x'])\n",
    "y = pd.Series(X['x']*X['x']+np.random.uniform(low=-20, high=20, size=(100,)))\n",
    "sns.scatterplot(x=X['x'], y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: definir la función 'muestra_modelo' que muestre cómo se adapta un modelo de regresión a los datos\n",
    "#   ENTRADA:\n",
    "#      - regresor: estimador para entrenar el modelo\n",
    "#      - X: atributos del dataset (dataframe con una única columna)\n",
    "#      - y: vector de salida para la regresión\n",
    "#      - tiulo: mensaje a mostrar en el título de la gráfica, \n",
    "#               se mostrará también la métrica obtenida con la función 'experimento'\n",
    "#      - subplot: 3-tupla con el subplot donde colocar la gráfica (por defecto None)\n",
    "#               INCLUIR AL PRINCIPIO:\n",
    "#                       if subplot!=None:\n",
    "#                           plt.subplot(subplot[0], subplot[1], subplot[2])\n",
    "#               INCLUIR AL FINAL:\n",
    "#                       if subplot==None:\n",
    "#                           plt.show()   \n",
    "#      \n",
    "#   SALIDA:\n",
    "#   - Nube de puntos del dataset, sobre la que se superpone (con trazo en rojo) la línea de prediccciones del modelo\n",
    "def muestra_modelo(estimador, X, y, titulo=\"\", subplot=None):\n",
    "    if subplot!=None:\n",
    "        plt.subplot(subplot[0], subplot[1], subplot[2])\n",
    "    if titulo==\"\":\n",
    "        titulo = estimador.__class__\n",
    "    modelo = estimador.fit(X, y)\n",
    "    min_x = X.min()\n",
    "    max_x = X.max()\n",
    "    xs = pd.DataFrame(np.linspace(min_x, max_x, 1000), columns=['x'])\n",
    "    y_pred = modelo.predict(xs)\n",
    "    sns.scatterplot(x=X['x'], y=y, color='blue')\n",
    "    sns.lineplot(x=xs['x'], y=y_pred, color='red')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    score, _ = experimento(estimador, X, y)\n",
    "    plt.title(\"{}   ({:.4f})\".format(titulo,score))\n",
    "    if subplot==None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: usar la función muestra_modelo para trazar la curva aprendida por un regresor lineal\n",
    "def experimento(regresor, X, y, scoring='r2'):\n",
    "    inicio = time.time()\n",
    "    score = cross_val_score(regresor, X, y, cv=10, scoring='r2').mean()\n",
    "    fin = time.time()\n",
    "    return score, fin-inicio\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "muestra_modelo(DecisionTreeRegressor(), X, y, titulo=\"Árbol\")\n",
    "muestra_modelo(LinearRegression(), X, y, titulo=\"Regresor Lineal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Curvas de aprendizaje en función del tamaño del conjunto de entrenamiento<a name=\"curva_dataset\"> </a>\n",
    "La funcion <code>learning_curve</code> nos permite analizar de qué manera afecta el tamaño del conjunto de entrenamiento en el rendimiento de un estimador. Se trata de ir entrenando modelos con _subconjuntos del dataset original_ de distintos tamaños. Esta función produce dos tipos de resultados:\n",
    "- **Resultados sobre el conjunto de entrenamiento**: se usan los mismos datos para entrenar y evaluar \n",
    "- **Resultados de validación**: se usan distintos datos para entrenar y evaluar\n",
    "\n",
    "Estas curvas pueden desvelar ciertas **tendencias al overfitting** y son muy útiles para detectar situaciones de **alto sesgo** y **alta varianza**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar el resultado de la función learning_curve para la siguiente configuración:\n",
    "#    - Estimador: ExtraTreesRegressor\n",
    "#    - Porcentaje dedicado a entrenamiento: 80%\n",
    "#    - Tamaño del subconjunto del dataset más pequeño: 10 (de un dataset con 100 instancias)\n",
    "#    - Número de subconjuntos a probar: 20\n",
    "#    - Método de scoring: 'r2'\n",
    "#    - Número de carpetas de la validación cruzada: 5\n",
    "# NOTA: seguir los siguientes pasos\n",
    "#    - Calcular tamaño_train y tamaño_test a partir de len(X) y del porcentaje de train\n",
    "#    - Usar no.linespace para calcular una lista de tamaños linealmente crecientes para todos los subconjuntos\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "estimador = ExtraTreesRegressor()\n",
    "#estimador = LinearRegression()\n",
    "\n",
    "porcentaje train = 80\n",
    "tamaño_inicial = 10\n",
    "numero_subconjuntos = 20\n",
    "scoring = 'r2'\n",
    "Cv = 5\n",
    "\n",
    "tamaño_train = int(len(X) * porcentaje_train / 100)\n",
    "tamaño_test = len(X) - tamaño_train\n",
    "tamaños_subconjuntos = np. linspace(tamaño_inicial, tamaño_train, numero_ subconjuntos, dtype = int)\n",
    "_,scores_train, scores_validacion = learning_ curve(estimador, X, y, train_sizes=tamaños_ subconjuntos)\n",
    "\n",
    "print (scores_train)\n",
    "print (scores_validacion)\n",
    "#foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: repetir el ejercicio calculando la media de cada fila (correspondiente a las validaciones cruzadas de cada experimento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO: definir la función 'muestra_curva_aprendizaje_tamaño' que muestre este tipo de curvas\n",
    "#   ENTRADA:\n",
    "#    - estimador: sobre el que se realiza el experimento\n",
    "#    - porcentaje_train: porcentaje dedicado a entrenamiento\n",
    "#    - tamaño_inicial: del primer subconjunto de entrenamiento\n",
    "#    - numero_subconjuntos: se calcularña un punto de la curva por cada subconjunto\n",
    "#    - scoring: método de scoring (por defecto 'r2')\n",
    "#    - cv: número de carpetas de la validación cruzada (por defecto 5)\n",
    "#    - subplot: 3-tupla con el subplot donde colocar la gráfica (por defecto None)\n",
    "#               INCLUIR AL PRINCIPIO:\n",
    "#                       if subplot!=None:\n",
    "#                           plt.subplot(subplot[0], subplot[1], subplot[2])\n",
    "#               INCLUIR AL FINAL:\n",
    "#                       if subplot==None:\n",
    "#                           plt.show()\n",
    "#    - rango_y: valores mínimo y máximo del eje y (por defecto None)\n",
    "#   SALIDA:\n",
    "#   - Curva de aprendizaje con trazo discontinuo rojo para entrenamiento, y continuo azul para validación\n",
    "\n",
    "def muestra_curva_aprendizaje_tamaño_simple(Estimador, X, y, porcentaje_train, tamaño_inicial, numero_subconjuntos, scoring='r2', cv=5, subplot=None):\n",
    "    \n",
    "    tamaño_train = int(len(X)*porcentaje_train/100)\n",
    "    tamaño_test = len(X) - tamaño_train\n",
    "    tamaños_subconjuntos = np. linspace(tamaño_inicial, tamaño_train, numero_subconjuntos, dtype = int)\n",
    "    _, scores_train, scores_validacion = learning_curve(estimador, X, y, train_sizes=tamaños_subconjuntos,\n",
    "                                                         cv=5, scoring='r2', shuffle=True)\n",
    "    scores_train = np.mean(scores_train, axis=1)\n",
    "    scores_validacion = np.mean(scores_validacion, axis=1)\n",
    "    \n",
    "    valores = tamaños_subconjuntos\n",
    "    plt.plot(valores, scores_train, 'r', linestyle='--', label=scoring+\" en 'entrenamiento'\") \n",
    "    plt.plot(valores, scores_validacion, 'b', label=scoring+\" en 'validación'\")\n",
    "    plt. title('Curva de aprendizaje sobre tamaño')\n",
    "    plt. legend()\n",
    "    \n",
    "muestra_curva_aprendizaje_tamaño_simple(LinearRegression(), X, y, 80, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la curva de aprendizaje para la regresión lineal. Usar la siguiente configuración:\n",
    "#    - porcentaje de train: 80\n",
    "#    - tamaño de conjunto inicial: 20\n",
    "#    - número de conjuntos: 20 con la siguiente configuración\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejercicio mostraremos, dos a dos, las curvas de modelo y de aprendizaje para distintos regresores. Las claves para intepretar los distintos fenómenos sobre las curvas de aprendizaje son:\n",
    "- **overfitting**: los resultados sobre entrenamiento son muy buenos (rozando el máximo) y los de validación son sensiblemente peores\n",
    "- **buen ajuste**: las curvas tienden a converger y se observa aún cierta tendencia al alza en la validación\n",
    "- **alta varianza**: las curvas tienen muchos picos, es señal de una gran dependencia de los datos\n",
    "- **alto sesgo**: la media de resultados es baja, y no hay tendencia a mejorar con el incremento de tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la curva de aprendizaje y la de modelo para los siguientes regresores:\n",
    "# - Regresión Lineal\n",
    "# - Regresión lineal con Stochastic Gradient Descent Regressor\n",
    "# - Regresión cuadrática basada en Regresión Lineal (hay que usar Pipeline y PolynomialFeatures)\n",
    "# - Vecinos más cercanos, con valores para k en [1, 3, 5, 7]\n",
    "# - Support Vector Regression, con valores para kernel en ['linear', ‘poly’, ‘rbf’, ‘sigmoid’]\n",
    "# - Stochastic Gradient Descent\n",
    "# - Árbol de decisión\n",
    "# - Random Forests, con valores para n_estimators en [10, 100, 1000]\n",
    "# - Extra trees, con valores para n_estimators en [10, 100, 1000]\n",
    "# - Gradient Boosting Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Curvas de aprendizaje en función de la complejidad del modelo<a name=\"curva_complejidad\"> </a>\n",
    "\n",
    "Sklearn proporciona la funcion <code>validation_curve</code> que nos permite analizar de qué manera afectan los valores que toma un hiperparámetro (que en muchos casos se puede interpretar como una medida de la complejidad del modelo) en el rendimiento de un estimador. Esta función produce dos conjuntos de resultados:\n",
    "- **Resultados sobre el conjunto de entrenamiento**: se usan los mismos datos para entrenar y evaluar \n",
    "- **Resultados de validación**: se usan distintos datos para entrenar y evaluar\n",
    "\n",
    "Esto nos permite identificar situaciones de **overfitting** cuando hay mucha discrepancia (en modelos complejos) entre los resultados de validación y los del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar el resultado de la función validation_curve para la siguiente configuración:\n",
    "#    - Estimador: ExtraTreesRegressor\n",
    "#    - Parámetro a evaluar: 'max_depth'\n",
    "#    - Valores del parámetro: [1, 2, 3, 4, 5, 10, 20, 50]\n",
    "#    - Método de scoring: 'r2'\n",
    "#    - Número de carpetas de la validación cruzada: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: repetir el ejercicio calculando la media de cada fila (correspondiente a las validaciones cruzadas de cada experimento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: definir la función 'muestra_curva_aprendizaje_complejidad' que muestre este tipo de curvas\n",
    "#   ENTRADA:\n",
    "#    - estimador: sobre el que se realiza el experimento\n",
    "#    - nombre_parametro: parámetro a evaluar\n",
    "#    - valores_parametros: para los que se calcularán puntos de la curva\n",
    "#    - scoring: método de scoring (por defecto 'r2')\n",
    "#    - cv: número de carpetas de la validación cruzada (por defecto 5)\n",
    "#    - subplot: 3-tupla con el subplot donde colocar la gráfica (por defecto None)\n",
    "#               INCLUIR AL PRINCIPIO:\n",
    "#                       if subplot!=None:\n",
    "#                           plt.subplot(subplot[0], subplot[1], subplot[2])\n",
    "#               INCLUIR AL FINAL:\n",
    "#                       if subplot==None:\n",
    "#                           plt.show()\n",
    "#     - rango_y: valores mínimo y máximo del eje y (por defecto None)\n",
    "#   SALIDA:\n",
    "#   - Curva de aprendizaje con trazo discontinuo rojo para entrenamiento, y continuo azul para validación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes ejercicios mostraremos las curvas de modelo y de aprendizaje para distintos regresores. Las claves para intepretar los distintos fenómenos sobre las curvas de aprendizaje son:\n",
    "- **overfitting**: valores del parámetro que provocan diferencias significativa de resultados entre train y validación\n",
    "- **underfitting**: valores del parámetro que provocan bajos resultados en train y validación\n",
    "- **buen ajuste**: valores del parámetro que provocan resultados coincidentes (y buenos) entre train y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la curva de aprendizaje para ExtraTreesRegressor y max_depth con valores en [1, 2, 3, 4, 5, 10, 20, 50]\n",
    "#            mostrar en otra figura las siguientes curvas de modelo de ExtraTreesRegressor:\n",
    "#               - Underfitting con max_depth=1, en subplot (1,3,1)\n",
    "#               - Buen ajuste con max_depth=5, en subplot (1,3,2)\n",
    "#               - Overfitting con ax_depth=50, en subplot (1,3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la curva de aprendizaje para KNeighborsRegressor() y n_neighbors con valores en range(1,50)\n",
    "#            mostrar en otra figura las siguientes curvas de modelo de KNeighborsRegressor:\n",
    "#               - Underfitting con k=50, en subplot (1,3,1)\n",
    "#               - Buen ajuste con k=15, en subplot (1,3,2)\n",
    "#               - Overfitting con k=1, en subplot (1,3,3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
