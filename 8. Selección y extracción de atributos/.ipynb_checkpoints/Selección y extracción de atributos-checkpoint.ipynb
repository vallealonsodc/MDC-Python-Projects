{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección y extracción de atributos\n",
    "**Autor:** José A. Troyano &nbsp;&nbsp;&nbsp; **Revisor:** Beatriz Pontes  &nbsp;&nbsp;&nbsp; **Última modificación:** 17/04/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "## Contenido\n",
    "\n",
    "\n",
    "1. <a href=\"#dataset\">Dataset y procedimiento de evaluación</a> <br>\n",
    "    1.1 <a href=\"#ruido\">Generación de atributos con ruido</a> <br>\n",
    "    1.2 <a href=\"#experimento\">Diseño de los experimentos</a>\n",
    "2. <a href=\"#univariante\">Selección univariante</a> <br>\n",
    "    2.1 <a href=\"#anova\">Test ANOVA</a> <br>\n",
    "    2.2 <a href=\"#otros\">Otros tests disponibles en Sklearn</a>\n",
    "3. <a href=\"#estimadores\">Selección de atributos basada en estimadores</a><br>\n",
    "    3.1 <a href=\"#arboles\">Mediante árboles</a><br>\n",
    "    3.2 <a href=\"#coeficientes\">Mediante coeficientes de modelos lineales</a><br>\n",
    "    3.3 <a href=\"#pipelines\">_Pipelines_ para encadenar selección y clasificación</a><br>\n",
    "4. <a href=\"#pca\">Extracción de atributos mediante análisis de componentes principales</a><br>\n",
    "5. <a href=\"#rfe\">Selección de atributos por eliminación recursiva</a><br>\n",
    "6. <a href=\"#conclusiones\">Conclusiones</a>\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook veremos cómo reducir el número de atributos de nuestro dataset. Lucharemos con lo que se conoce como _curse of dimensionality_ que tiene básicamente estos efectos:\n",
    "- Cuando aumenta la dimensionalidad, el volumen del espacio aumenta exponencialmente haciendo que los datos disponibles se vuelvan dispersos. \n",
    "- Esta dispersión impide que los algoritmos de aprendizaje puedan construir buenos modelos.\n",
    "\n",
    "La selección y extracción de atributos son dos estrategias típicas para luchar con la maldición de la dimensionalidad. Se basan, respectivamente, en la elección de un buen subconjunto de atributos y en la construcción de nuevos atributos a partir de los originales.\n",
    "\n",
    "Empezaremos por importar todos los elementos que usaremos a lo largo del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, chi2\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, SelectFromModel\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset y procedimiento de evaluación <a name=\"dataset\"> </a>\n",
    "\n",
    "Usaremos el dataset _breast-cancer_, disponible en Sklearn que tiene:\n",
    "- 569 instancias\n",
    "- 30 atributos numéricos\n",
    "- Una clase discreta con dos posibles valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Empezaremos por leer el dataset desde Sklearn y crear 'X' e 'y'\n",
    "DATOS = load_breast_cancer()\n",
    "X = pd.DataFrame(DATOS['data'], columns=DATOS['feature_names'])\n",
    "y = pd.Series(DATOS['target'])\n",
    "print(y.describe())\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Generación de atributos con ruido <a name=\"ruido\"> </a>\n",
    "\n",
    "\n",
    "Para asegurarnos que hay atributos que deben ser eliminados crearemos una versión ofuscada de este dataset con 30 columnas aleatorias. Esta versión presenta, por tanto, estos números:\n",
    "- 569 instancias\n",
    "- 60 atributos numéricos\n",
    "- Una clase discreta con dos posibles valores\n",
    "\n",
    "Si quisiésemos probar todas los posibles subconjuntos de 60 atributos para encontrar el mejor, tendríamos que probar $2^{60}$ combinaciones, que nos da un total de $11 \\times 10^{17}$ experimentos. Si cada experimento durase un segundo, tendríamos que esperar 36.000 millones de años para ejecutarlos todos. Gracias a la selección y extracción de atributos tenemos estrategias para encontrar un buen conjunto de atributos (no el mejor) en un tiempo razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Generaremos una matriz 'X_RUIDOSOS' que contenga las columnas de 'X' junto con 30 columnas aleatorias. Para generar los atributos aleatorios:\n",
    "#   - Usamos np.random.RandomState(100) como objeto semilla\n",
    "#   - Usamos una distribución uniforme para generar valores entre 0 y 50           \n",
    "semilla_aleatoria = np.random.RandomState(100)\n",
    "DATOS_RUIDOSOS= semilla_aleatoria.uniform(0, 50, size=(len(X), 30))\n",
    "nombres = ['R-'+str(i) for i in range(30)]\n",
    "DATOS_RUIDOSOS = pd.DataFrame(DATOS_RUIDOSOS, columns=nombres)\n",
    "X_RUIDOSOS = pd.concat([X, DATOS_RUIDOSOS], axis=1)\n",
    "print(X_RUIDOSOS.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Diseño de los experimentos\n",
    "\n",
    "La función <code>evalua</code> realiza la evaluación de un clasificador (por defecto <code>LogisticRegresion</code>) sobre un dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluamos ambos datasets para tener los baselines\n",
    "def evalua(X, y, clasificador=LogisticRegression()):\n",
    "    ''' Función para evaluar un dataset mediante validación cruzada\n",
    "    \n",
    "    Por defecto se usa el clasificador LogisticRegression, aunque se puede cambiar.\n",
    "    '''\n",
    "    scores = cross_val_score(clasificador, X, y, cv=10)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos por evaluar <code>X</code> y <code>X_RUIDOSOS</code> para tener así una referencia del efecto de las distintas técnicas de selección de atributos que vamos a probar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluamos ambos datasets para tener los baselines y creamos el dataframe RESULTADOS\n",
    "RESULTADOS = pd.DataFrame(columns=['X', 'Mejora para X', 'X_RUIDOSOS', 'Mejora para X_RUIDOSOS'])\n",
    "\n",
    "RESULTADOS.loc['Sin selección'] = (evalua(X,y), '--', evalua(X_RUIDOSOS,y), '--')\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La siguiente función nos permitirá evaluar la mejora conseguida por un determinado selector sobre los datasets X y X_RUIDOSOS\n",
    "#     PARÁMETROS:\n",
    "#       - selector: estimador usado en la selección para el experimento\n",
    "#       - X: matriz de atributos original\n",
    "#       - X_ruidosos: matriz de atributos ruidosos\n",
    "#       - y: vector de salida\n",
    "#    VARIABLES INTERMEDIAS:\n",
    "#       - X_seleccion: resultado de aplicar el selector a X\n",
    "#       - X_ruidosos_seleccion: resultado de aplicar el selector a X_ruidosos\n",
    "#    RESULTADO: tupla con los siguientes valores\n",
    "#       - Resultado de: evalua(X_seleccion, y)\n",
    "#       - Resultado de: evalua(X, y) - evalua(X_seleccion, y)\n",
    "#       - Resultado de: evalua(X_ruidosos_seleccion, y)\n",
    "#       - Resultado de: evalua(X_ruidosos, y) - evalua(X_ruidosos_seleccion, y)\n",
    "\n",
    "def experimento_seleccion(selector, X, X_ruidosos, y):\n",
    "    X_seleccion = selector.fit_transform(X, y)\n",
    "    X_ruidosos_seleccion = selector.fit_transform(X_ruidosos, y)\n",
    "    return (evalua(X_seleccion, y), evalua(X_seleccion, y) -  evalua(X, y),\n",
    "            evalua(X_ruidosos_seleccion, y), evalua(X_ruidosos_seleccion, y)-evalua(X_ruidosos, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, en la siguiente celda se incluyen un par de funciones que nos ayudarán a interpretar los resultados de las distintas técnicas de selección de atributos que vamos a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def muestra_relevancias(nombres, relevancias):\n",
    "    '''Función para mostrar una gráfica con el grado de relevancia de cada atributo\n",
    "    \n",
    "    Recibe:\n",
    "       - nombres: nombres de todos los atributos\n",
    "       - relevancias: de cada atributo, calculadas mediante alguna técnica\n",
    "    '''\n",
    "    plt.figure(figsize=(len(nombres)/4,5))\n",
    "    serie = pd.Series(relevancias, index=nombres)\n",
    "    serie.plot(kind='bar')\n",
    "    \n",
    "def muestra_seleccion(nombres, mascara):\n",
    "    '''Función para mostrar los nombres de los atributos seleccionados a partir de una máscara de booleanos\n",
    "    \n",
    "    Recibe:\n",
    "       - nombres: nombres de todos los atributos\n",
    "       - mascara: lista de booleanos que determina si un atributo se selecciona, o no\n",
    "    '''    \n",
    "    seleccionados = [n for n,m in zip(nombres, mascara) if m]\n",
    "    print(len(seleccionados), seleccionados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selección univariante <a name=\"univariante\"> </a>\n",
    "\n",
    "En esta sección veremos formas de valorar qué importancia tiene cada atributo de forma individual. Para ello nos apoyaremos en tests estadísticos que miden la relación de cada atributo con la clase a predecir (o valor numérico en caso de regresión). Estos tests se diseñan para rechazar la siguiente hipótesis nula:\n",
    "\n",
    "- $H_0$: el atributo no es relevante.\n",
    "\n",
    "En <code>sklearn</code> estos tests se implementan mediante funciones que producen dos valores:\n",
    "- **Estadístico**: una medida numérica que se calcula a partir de los datos, que se utiliza para tomar una decisión sobre la hipótesis nula (el atributo no es relevante). \n",
    "- **P-valor**: la probabilidad de no poder rechazar la hipótesis nula. Cuanto más bajo sea el *p-valor* es menos probable es que el resultado del test se deba al azar, y es más probable que haya un efecto real (que el atributo sea relevante).\n",
    "\n",
    "Podemos usar cualquiera de los dos como criterio de selección, ambos nos ofrencen el mismo *ranking* de atributos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Test ANOVA <a name=\"anova\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar el grado de relevancia de cada atributo del datastet X mediante el test ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los atributos de X cuyos pvalues obtenidos por el test ANOVA sean menores o iguales que 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los atributos de X cuyos pvalues obtenidos por el test ANOVA sean mayores que 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar el grado de relevancia de cada atributo del datastet X_RUIDOSOS mediante el test ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la selección de la primera mitad de atributos (el 50% mejor) para X según el test ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la selección de la primera mitad de atributos (el 50% mejor) para X_RUIDOSOS según el test ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la selección de los 10 mejores atributos para X según el test ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: \n",
    "#   - Obtener una matriz X_RUIDOSOS_seleccion con los 30 mejores atributos del dataset X_RUIDOSOS según ANOVA\n",
    "#   - Guardar el resultado con:\n",
    "#          RESULTADOS.loc['ANOVA - 30'] = experimento_seleccion(selector, X, X_RUIDOSOS, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular los resultados del experimento de selección con los 20 mejores atributos según ANOVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Otros tests disponibles en Sklearn <a name=\"otros\"> </a>\n",
    "Además del test ANOVA que hemos visto en esta sección, Sklearn proporciona otras funciones de valoración de atributos tanto para tareas de clasificación como de regresión. Para clasificación, las funciones disponibles son:\n",
    "\n",
    "- <code>f_classif</code>: valor-f del test ANOVA \n",
    "- <code>chi2</code>: test $\\chi^2$ (solo para atributos positivos)\n",
    "- <code>mutual_info_classif</code>: información mutua entre dos variables\n",
    "\n",
    "Para regresión, por su parte, disponemos de estas funciones:\n",
    "\n",
    "- <code>f_regression</code>: valor-f obtenido mediante regresión lineal\n",
    "- <code>mutual_info_regression</code>: información mutua entre dos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular los resultados del experimento de selección con los siguientes selectores\n",
    "#    'Chi2-30' : con los 30 primeros atributos según chi2\n",
    "#    'Chi2-20' : con los 20 primeros atributos según chi2\n",
    "#    'Mutual Info-30' : con los 30 primeros atributos según mutual_info_classif\n",
    "#    'Mutual Info-20' : con los 20 primeros atributos según mutual_info_classif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selección de atributos basada en estimadores <a name=\"estimadores\"> </a>\n",
    "\n",
    "Algunos algoritmos de clasificación (y también de regresión), además de construir un modelo, son capaces de puntuar la importancia de los atributos al mismo tiempo. Esa puntuación es un buen indicador para determinar qué atributos seleccionar. Las dos familias de algoritmos que se suelen usar para esta técnica son:\n",
    "- Algoritmos basados en árboles: la importancia se calcula sobre el número de veces que se usa cada atributo como criterio y la profundidad en la que aparecen en los árboles.\n",
    "- Modelos lineales generalizados: la importancia se calcula a partir de los coeficientes aprendidos para cada atributo para construir el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Selección de atributos mediante árboles <a name=\"arboles\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la importancia de atributos de X_RUIDOSOS calculada por un clasificador RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los atributos de X_RUIDOSOS seleccionados por SelectFromModel sobre el clasificador RFC\n",
    "#    - Usar como threshold la media de las importancias de atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los atributos de X_RUIDOSOS seleccionados por SelectFromModel sobre el clasificador RFC\n",
    "#    - Usar como threshold la mitad de la media de las importancias de atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los atributos de X_RUIDOSOS seleccionados por SelectFromModel sobre el clasificador RFC\n",
    "#    - Usar como threshold la mediana de las importancias de atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular los resultados del experimento de selección con los siguientes selectores\n",
    "#    'Random Forest - mean' : con los atributos que superen la media de la importancia de un clasificador Random Forest\n",
    "#    'Random Forest - median' : con los atributos que superen la mediana de la importancia de un clasificador Random Forest\n",
    "#    'Random Forest - 15' : con los 15 mejores atributos según la importancia de un clasificador Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Selección de atributos mediante coeficientes de modelos lineales <a name=\"coeficientes\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los coeficientes de los atributos de X_RUIDOSOS calculados por LogisticRegression con regularización 'l1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar los atributos de X_RUIDOSOS seleccionados por SelectFromModel sobre el clasificador LR('l1')\n",
    "#    - Usar como threshold la mediana de las importancias de atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular los resultados del experimento de selección con los siguientes selectores\n",
    "#    'L1 - mean' : con los atributos que superen la media de los coeficientes de una regresión logística\n",
    "#    'L1 - median' : con los atributos que superen la mediana de los coeficientes de una regresión logística\n",
    "#    'L1 - 15' : con los 15 mejores atributos según los coeficientes de una regresión logística\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 _Pipelines_ para encadenar selección y clasificación <a name=\"pipelines\"> </a>\n",
    "\n",
    "Mediante los pipelines se pueden encadenar estimadores que se entrenan de forma conjunta. Si hacemos un <code>predict</code> sobre un pipeline, para los $n-1$ primeros estimadores se aplicará <code>transform</code> y para el último <code>predict</code>.\n",
    "\n",
    "Los pipelines se comportan a todos los efectos como estimadores pudiéndose, por ejemplo, realizar validación cruzada sobre ellos con <code>cross_val_predict</code> o <code>cross_val_score</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: consrtuir un pipeline con los siguientes componentes:\n",
    "#    - Un selector sobre RFC y usando la mediana como threshold\n",
    "#    - Un clasificador LogisticRegression\n",
    "# Guardar en RESULTADOS con la siguiente instrucción:\n",
    "#      RESULTADOS.loc['RFC+LR'] = (evalua(X,y,pipeline), evalua(X,y,pipeline)-evalua(X,y),evalua(X_RUIDOSOS,y,pipeline), evalua(X_RUIDOSOS,y,pipeline)-evalua(X_RUIDOSOS,y))                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: consrtuir un pipeline con los siguientes componentes:\n",
    "#    - Un selector sobre LogisticRegression usando la mediana como threshold\n",
    "#    - Un clasificador RFC\n",
    "# Guardar en RESULTADOS con la siguiente instrucción:\n",
    "#      RESULTADOS.loc['LR+RFC'] = (evalua(X,y,pipeline), evalua(X,y,pipeline)-evalua(X,y),evalua(X_RUIDOSOS,y,pipeline), evalua(X_RUIDOSOS,y,pipeline)-evalua(X_RUIDOSOS,y))                                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracción de atributos mediante _análisis de componentes principales_ <a name=\"pca\"> </a>\n",
    "\n",
    "El análisis de componentes principales es es una técnica que permite describir un dataset en términos de nuevos atributos (los componentes) que no estén correlacionados. Cada una de estas nuevas columnas se ordenan por la cantidad de varianza que captura de los datos originales, y esta importancia nos puede servir para quedarnos con un número más pequeño de características.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular los resultados del experimento de selección con los siguientes selectores\n",
    "#    'PCA - 25' : con los nuevos atributos exraidos con PCA(25)\n",
    "#    'PCA - 20' : con los nuevos atributos exraidos con PCA(20)\n",
    "#    'PCA - 15' : con los nuevos atributos exraidos con PCA(15)\n",
    "#    'PCA - 10' : con los nuevos atributos exraidos con PCA(10)\n",
    "#    'PCA - 5' : con los nuevos atributos exraidos con PCA(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear una función que pruebe el efecto de distintos valores de n_components (de 1 a un límite dado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST: de la función 'evolucion_n_components' sobre X\n",
    "evolucion_n_components(X, y, len(X.columns))\n",
    "\n",
    "# TEST: de la función 'evolucion_n_components' sobre X_RUIDOSOS\n",
    "evolucion_n_components(X_RUIDOSOS, y, len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: aplicar PCA(10) sobre X_RUIDOSOS y mostrar la proporción de varianza capturada por cada componente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selección de atributos por _eliminación recursiva_ <a name=\"rfe\"> </a>\n",
    "\n",
    "La eliminación recursiva de características (RFE de _recursive feature elimination_) se apoya en un clasificador base al igual que ocurre en la selección mediante importancia de atributos. En este caso los atributos se van descartando uno a uno, dejando fuera el que es peor en cada momento. Es una técnica computacionalmente un pocos costosa (el coste depende del clasificador base) pero suele dar buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: entrenar un selector RFE sobre X usando como clasificador base LogisticRegression, y mostrar el ranking de atributos resultante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Función para construir una lista ordenada de los nombres de atributos a partir de un ranking y su correspondiente matriz X\n",
    "def ranking_nombres_atributos(ranking, nombres_atributos):\n",
    "    posiciones_atributos = list(zip(ranking, list(nombres_atributos)))\n",
    "    posiciones_atributos.sort()\n",
    "    return([a for _,a in posiciones_atributos])\n",
    "\n",
    "ranking_nombres_atributos(ranking_X, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Función que prueba el efecto de eliminar uno a uno los peores atributos de una matriz X\n",
    "def evolucion_quitando_peor_atributo(X, y, selector_rfe):\n",
    "    ''' Quita uno a uno los peores atributos y evalua el dataset que va quedando\n",
    "    \n",
    "    Entrada:\n",
    "       - X: dataframe con los atributos\n",
    "       - y: serie con la clase\n",
    "       - selector_rfe: selector RFE usado\n",
    "    Salida:\n",
    "       - Gráfica con la evolución\n",
    "       - Mejor resultado obtenido\n",
    "    '''\n",
    "    selector_rfe.fit(X,y)\n",
    "    ranking = selector_rfe.ranking_\n",
    "    resultados = []\n",
    "    atributos_seleccionados = ranking_nombres_atributos(ranking, X.columns)\n",
    "    for i in range(len(ranking)):\n",
    "        #print(atributos_seleccionados[-1])\n",
    "        X_sel = X[atributos_seleccionados]\n",
    "        resultado = evalua(X_sel, y)\n",
    "        resultados.append(resultado)\n",
    "        atributos_seleccionados = atributos_seleccionados[:-1]\n",
    "    plt.plot(resultados)\n",
    "    plt.show()\n",
    "    return(max(resultados))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: usar la función 'evolucion_quitando_peor_atributo' sobre X y X_RUIDOSOS con un selector RFE basado en LogisticRegression\n",
    "#   Calcular las siguientes variables:\n",
    "#      - resultado_X: resultado sobre X sin selección\n",
    "#      - resultado_X_seleccion: mejor resultado obtenido sobre X en la secuencia de experimentos RFE\n",
    "#      - resultado_X_RUIDOSOS: resultado sobre X_RUIDOSOS sin selección\n",
    "#      - resultado_X_RUIDOSOS_seleccion: mejor resultado obtenido sobre X_RUIDOSOS en la secuencia de experimentos RFE\n",
    "# Guardar en RESULTADOS con la siguiente instrucción:\n",
    "#      RESULTADOS.loc['RFE - LR'] = (resultado_X_seleccion, resultado_X_seleccion-resultado_X, resultado_X_RUIDOSOS_seleccion, resultado_X_RUIDOSOS_seleccion-resultado_X_RUIDOSOS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones <a name=\"conclusiones\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las técnicas han funcionado bien para los datos ruidosos, con las siguientes mejoras significativas:\n",
    "- **Pipeline LR-RFC**: mejora un 3.0%\n",
    "- **RFE**: mejora un 2.6%\n",
    "- **Información mutua**: mejora un 1.9%\n",
    "- **ANOVA**: mejora un 1.9%\n",
    "- **Random Forest**: mejora a un 1.7%\n",
    "- **Pipeline RFC-LR**: mejora un 1.7%\n",
    "- **Coeficientes lineales**: mejora un 1.4%\n",
    "- **Chi2**: mejora un 1.2%\n",
    "    \n",
    "No hay apenas mejora en los datos originales:\n",
    "- En el caso de los datos ruidosos sabíamos positivamente que había columnas que quitar, por lo que es razonable el resultado.\n",
    "- Para los datos originanes estos resultados nos están sugiriendo que el conjunto de atributos originales era bastante bueno.\n",
    "\n",
    "En cuanto a la utilidad y potencia de cada método, no podemos sacar conclusiones generales. En _machine learning_ impera la máxima _one size does not fit all_, y lo que funciona para un dataset no es seguro que funcione para otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
